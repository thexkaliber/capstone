{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import numpy as np\n",
    "import torch\n",
    "from astropy.table import Table\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "sys.path.append(\"../..\")\n",
    "\n",
    "from astroclip.env import format_with_env\n",
    "from property_utils.models import few_shot, zero_shot\n",
    "from property_utils.plotting import plot_scatter\n",
    "\n",
    "ASTROCLIP_ROOT = \"/workspace/astroclip/\"\n",
    "\n",
    "PROVABGS_ROOT = f\"/workspace/astroclip/data/\"\n",
    "# SUPERVISED_ROOT = f\"{ASTROCLIP_ROOT}/supervised/\"\n",
    "ASTROCLIP_ROOT = \"/workspace/astroclip\"\n",
    "PRETRAINED_ROOT = f\"{ASTROCLIP_ROOT}\"\n",
    "PROVABGS_ROOT = f\"{ASTROCLIP_ROOT}/data/\"\n",
    "# Define models in embeddings\n",
    "image_models = [\"astrodino\", \"xcit_encoder\",\"swin_encoder\",\"swinv2_encoder\", \"vim_encoder\"]\n",
    "spectrum_models =  [\"specformer\", \"astroclip_spectrum\"]\n",
    "\n",
    "# Set up the paths\n",
    "train_path = os.path.join(PROVABGS_ROOT, \"provabgs_train_ssl_embeddings.hdf5\")\n",
    "test_path = os.path.join(PROVABGS_ROOT, \"provabgs_test_ssl_embeddings.hdf5\")\n",
    "\n",
    "# Get embeddings and PROVABGS table\n",
    "train_provabgs = Table.read(train_path)\n",
    "test_provabgs = Table.read(test_path)\n",
    "\n",
    "# Get properties and scale\n",
    "properties = [\"Z_MW\", \"LOG_MSTAR\", \"TAGE_MW\", \"sSFR\"]\n",
    "y_train = np.stack([train_provabgs[prop].data.squeeze() for prop in properties]).T\n",
    "y_test = np.stack([test_provabgs[prop].data.squeeze() for prop in properties]).T\n",
    "scaler = {\"mean\": y_train.mean(axis=0), \"std\": y_train.std(axis=0)}\n",
    "y_train = (y_train - scaler[\"mean\"]) / scaler[\"std\"]\n",
    "\n",
    "print(\n",
    "    \"Size of training set:\",\n",
    "    len(train_provabgs),\n",
    "    \"\\nSize of test set:\",\n",
    "    len(test_provabgs),\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Galaxy Property Prediction from Image Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data\n",
    "data = {}\n",
    "for model in image_models:\n",
    "    data[model] = {}\n",
    "    X_train, X_test = (\n",
    "        train_provabgs[model + \"_embeddings\"],\n",
    "        test_provabgs[model + \"_embeddings\"],\n",
    "    )\n",
    "    X_train = X_train.reshape(X_train.shape[0],-1)\n",
    "    X_test = X_test.reshape(X_test.shape[0], -1)\n",
    "    embedding_scaler = StandardScaler().fit(X_train)\n",
    "    data[model][\"train\"] = embedding_scaler.transform(X_train)\n",
    "    data[model][\"test\"] = embedding_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating vim_encoder model...\n"
     ]
    }
   ],
   "source": [
    "# Perfrom knn and mlp\n",
    "preds_knn, preds_mlp = {}, {}\n",
    "for key in data.keys():\n",
    "    print(f\"Evaluating {key} model...\")\n",
    "    raw_preds_knn = zero_shot(data[key][\"train\"], y_train, data[key][\"test\"])\n",
    "    raw_preds_mlp = few_shot(\n",
    "        model, data[key][\"train\"], y_train, data[key][\"test\"]\n",
    "    ).squeeze()\n",
    "    preds_knn[key] = raw_preds_knn * scaler[\"std\"] + scaler[\"mean\"]\n",
    "    preds_mlp[key] = raw_preds_mlp * scaler[\"std\"] + scaler[\"mean\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a table of r^2 scores\n",
    "knn_prop = {key: [] for key in preds_knn.keys()}\n",
    "mlp_prop = {key: [] for key in preds_mlp.keys()}\n",
    "\n",
    "for key in preds_knn.keys():\n",
    "    for i, prop in enumerate(properties):\n",
    "        knn_prop[key].append(r2_score(y_test[:, i], preds_knn[key][:, i]))\n",
    "        knn_prop[key].append(mean_absolute_error(y_test[:, i], preds_knn[key][:, i]))\n",
    "        knn_prop[key].append(mean_squared_error(y_test[:, i], preds_knn[key][:, i]))\n",
    "        knn_prop[key].append(pearsonr(y_test[:, i], preds_knn[key][:, i])[0])\n",
    "        knn_prop[key].append(spearmanr(y_test[:, i], preds_knn[key][:, i])[0])\n",
    "\n",
    "        mlp_prop[key].append(r2_score(y_test[:, i], preds_mlp[key][:, i]))\n",
    "        mlp_prop[key].append(mean_absolute_error(y_test[:, i], preds_knn[key][:, i]))\n",
    "        mlp_prop[key].append(mean_squared_error(y_test[:, i], preds_knn[key][:, i]))\n",
    "        mlp_prop[key].append(pearsonr(y_test[:, i], preds_knn[key][:, i])[0])\n",
    "        mlp_prop[key].append(spearmanr(y_test[:, i], preds_knn[key][:, i])[0])\n",
    "knn_prop[\"properties\"] = properties\n",
    "mlp_prop[\"properties\"] = properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><i>Table length=4</i>\n",
       "<table id=\"table138873080040752\" class=\"table-striped table-bordered table-condensed\">\n",
       "<thead><tr><th>vim_encoder</th><th>properties</th></tr></thead>\n",
       "<thead><tr><th>float64</th><th>str9</th></tr></thead>\n",
       "<tr><td>0.024720143054751786</td><td>Z_MW</td></tr>\n",
       "<tr><td>0.05513223285710489</td><td>LOG_MSTAR</td></tr>\n",
       "<tr><td>-0.007044884187193734</td><td>TAGE_MW</td></tr>\n",
       "<tr><td>-1.072077465896021</td><td>sSFR</td></tr>\n",
       "</table></div>"
      ],
      "text/plain": [
       "<Table length=4>\n",
       "     vim_encoder      properties\n",
       "       float64           str9   \n",
       "--------------------- ----------\n",
       " 0.024720143054751786       Z_MW\n",
       "  0.05513223285710489  LOG_MSTAR\n",
       "-0.007044884187193734    TAGE_MW\n",
       "   -1.072077465896021       sSFR"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Table(knn_prop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><i>Table length=4</i>\n",
       "<table id=\"table138873080224336\" class=\"table-striped table-bordered table-condensed\">\n",
       "<thead><tr><th>vim_encoder</th><th>properties</th></tr></thead>\n",
       "<thead><tr><th>float64</th><th>str9</th></tr></thead>\n",
       "<tr><td>0.2985458852642845</td><td>Z_MW</td></tr>\n",
       "<tr><td>0.6053510601438861</td><td>LOG_MSTAR</td></tr>\n",
       "<tr><td>0.07179152455067772</td><td>TAGE_MW</td></tr>\n",
       "<tr><td>0.16810028903837704</td><td>sSFR</td></tr>\n",
       "</table></div>"
      ],
      "text/plain": [
       "<Table length=4>\n",
       "    vim_encoder     properties\n",
       "      float64          str9   \n",
       "------------------- ----------\n",
       " 0.2985458852642845       Z_MW\n",
       " 0.6053510601438861  LOG_MSTAR\n",
       "0.07179152455067772    TAGE_MW\n",
       "0.16810028903837704       sSFR"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Table(mlp_prop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions from supervised models\n",
    "resnet_preds = torch.load(\n",
    "    os.path.join(SUPERVISED_ROOT, \"image/ResNet18/global_properties/test_pred.pt\")\n",
    ")\n",
    "photometry_preds = torch.load(\n",
    "    os.path.join(SUPERVISED_ROOT, \"photometry/MLP/global_properties/test_pred.pt\")\n",
    ")\n",
    "\n",
    "# Add predictions to dictionary\n",
    "preds_supervised = {\n",
    "    \"resnet18\": np.stack([resnet_preds[prop].squeeze() for prop in properties]).T,\n",
    "    \"photometry\": np.stack([photometry_preds[prop].squeeze() for prop in properties]).T,\n",
    "}\n",
    "\n",
    "supervised_r2 = {key: [] for key in preds_supervised.keys()}\n",
    "for key in preds_supervised.keys():\n",
    "    for i, prop in enumerate(properties):\n",
    "        supervised_r2[key].append(r2_score(y_test[:, i], preds_supervised[key][:, i]))\n",
    "\n",
    "supervised_r2[\"properties\"] = properties\n",
    "Table(supervised_r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Galaxy Property Prediction from Spectrum Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data\n",
    "data = {}\n",
    "for model in spectrum_models:\n",
    "    data[model] = {}\n",
    "    X_train, X_test = (\n",
    "        train_provabgs[model + \"_embeddings\"],\n",
    "        test_provabgs[model + \"_embeddings\"],\n",
    "    )\n",
    "    embedding_scaler = StandardScaler().fit(X_train)\n",
    "    data[model][\"train\"] = embedding_scaler.transform(X_train)\n",
    "    data[model][\"test\"] = embedding_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perfrom knn and mlp\n",
    "preds_knn, preds_mlp = {}, {}\n",
    "for key in data.keys():\n",
    "    print(f\"Evaluating {key} model...\")\n",
    "    raw_preds_knn = zero_shot(data[key][\"train\"], y_train, data[key][\"test\"])\n",
    "    raw_preds_mlp = few_shot(\n",
    "        model, data[key][\"train\"], y_train, data[key][\"test\"]\n",
    "    ).squeeze()\n",
    "    preds_knn[key] = raw_preds_knn * scaler[\"std\"] + scaler[\"mean\"]\n",
    "    preds_mlp[key] = raw_preds_mlp * scaler[\"std\"] + scaler[\"mean\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a table of r^2 scores\n",
    "knn_r2 = {key: [] for key in preds_knn.keys()}\n",
    "mlp_r2 = {key: [] for key in preds_mlp.keys()}\n",
    "\n",
    "for key in preds_knn.keys():\n",
    "    for i, prop in enumerate(properties):\n",
    "        knn_prop[key].append(r2_score(y_test[:, i], preds_knn[key][:, i]))\n",
    "        knn_prop[key].append(mean_absolute_error(y_test[:, i], preds_knn[key][:, i]))\n",
    "        knn_prop[key].append(mean_squared_error(y_test[:, i], preds_knn[key][:, i]))\n",
    "        knn_prop[key].append(pearsonr(y_test[:, i], preds_knn[key][:, i])[0])\n",
    "        knn_prop[key].append(spearmanr(y_test[:, i], preds_knn[key][:, i])[0])\n",
    "\n",
    "        mlp_prop[key].append(r2_score(y_test[:, i], preds_mlp[key][:, i]))\n",
    "        mlp_prop[key].append(mean_absolute_error(y_test[:, i], preds_knn[key][:, i]))\n",
    "        mlp_prop[key].append(mean_squared_error(y_test[:, i], preds_knn[key][:, i]))\n",
    "        mlp_prop[key].append(pearsonr(y_test[:, i], preds_knn[key][:, i])[0])\n",
    "        mlp_prop[key].append(spearmanr(y_test[:, i], preds_knn[key][:, i])[0])\n",
    "knn_prop[\"properties\"] = properties\n",
    "mlp_prop[\"properties\"] = properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Table(knn_prop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Table(mlp_prop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions from supervised models\n",
    "spectrum_preds = torch.load(\n",
    "    os.path.join(SUPERVISED_ROOT, \"spectrum/Conv+Att/global_properties/test_pred.pt\")\n",
    ")\n",
    "\n",
    "# Add predictions to dictionary\n",
    "preds_supervised = {\n",
    "    \"conv+att\": np.stack([spectrum_preds[prop].squeeze() for prop in properties]).T,\n",
    "}\n",
    "\n",
    "supervised_r2 = {key: [] for key in preds_supervised.keys()}\n",
    "for key in preds_supervised.keys():\n",
    "    for i, prop in enumerate(properties):\n",
    "        supervised_r2[key].append(r2_score(y_test[:, i], preds_supervised[key][:, i]))\n",
    "\n",
    "supervised_r2[\"properties\"] = properties\n",
    "Table(supervised_r2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
